{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini: Una descripción general de los escenarios multimodales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visión General\n",
    "\n",
    "### Gemini\n",
    "\n",
    "Gemini es una familia de modelos generativos de IA desarrollados por Google DeepMind y diseñados para casos de uso multimodales. La API Gemini da acceso a los modelos Gemini Pro y Gemini Pro Vision\n",
    "\n",
    "### API Vertex AI Gemini\n",
    "\n",
    "La API Vertex AI Gemini nos da una interfaz unificada para interactuar con modelos Gemini. Actualmente existen dos modelos disponibles en la API Gemini:\n",
    "\n",
    "- **Modelos Gemini Pro** (`gemini-pro`): Diseñado para manejar tareas de lenguaje natural, chat multiturno de texto y código y generación de código.\n",
    "- **Modelo Gemini Pro Vision** (`gemini-pro-vision`): Soporta prompts multimodales. Puedes incluir texto, imágenes y video en los prompt y obtener respuestas en texto o código.\n",
    "\n",
    "Puedes interactuar con la API Gemini usando los siguientes métodos:\n",
    "\n",
    "- Usando [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) para pruebas rápidas y generación de contenidos de texto.\n",
    "- Usando el SDK de Vertex AI\n",
    "\n",
    "Esta libreta se concentra en el uso de **Vertex AI SDK para Python** para utilizar la API Vertex AI Gemini.\n",
    "\n",
    "Para obtener más información, consulta la documentación [IA Generativa en Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos\n",
    "\n",
    "Esta libreta demuestra una variedad de casos de uso multimodal para los que se puede utilizar Gemini.\n",
    "\n",
    "#### Casos de uso multimodales\n",
    "\n",
    "En comparación con los LLM (*Large Language Model*, modelos grandes de lenguaje) de sólo texto, la multimodalidad de Gemini Pro Vision se puede utilizar para muchos casos de uso nuevos:\n",
    "\n",
    "Ejemplos de casos de uso con **texto e imágenes** como entrada:\n",
    "\n",
    "- Detectar objetos en fotografías\n",
    "- Comprender las pantallas y las interfaces\n",
    "- Compresión de dibujos y abstracciones\n",
    "- Comprender gráficos y diagramas\n",
    "- Recomendación de imágenes basada en las preferencias del usuario\n",
    "- Comparar imágenes en busca de similitudes, anomalías o diferencias\n",
    "\n",
    "Ejemplos de casos de uso con **texto y video** como entrada:\n",
    "\n",
    "- Generar la descripción de un video\n",
    "- Extraer etiquetas de objetos a lo largo de un video\n",
    "- Extraer momentos destacados/mensajes de un video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costos\n",
    "\n",
    "Este tutorial usa los siguientes componentes de Google Cloud que pueden generar costos en su factura:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Para mayores detalles puedes revisar los [precios de Vertex AI](https://cloud.google.com/vertex-ai/pricing) y usar la [calculadora de precios](https://cloud.google.com/products/calculator/) para generar una estimación de costos con base en el uso del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sólo para uso en Colab - Autentica tu ambiente de trabajo**\n",
    "\n",
    "En el caso que estés ejecutando esta libreta en un Google Colab, descomenta la siguiente celda para realizar la autenticación de la sesión en la libreta con Google Cloud. Este paso es importante **para la utilización en Colab**, así podemos garantizar que las llamadas a las APIs de Google Cloud funcionen sin problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import sys\n",
    "# Autenticacion adicional se necesita en Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Autentica el usuario con Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sólo para uso en Colab - define el proyecto en Google Cloud a utilizar**\n",
    "\n",
    "En el caso que estés ejecutando esta libreta en Google Colab, descomenta la siguiente celda para definir qué proyecto en Google Cloud será usado por Colab en la ejecución de esta libreta. De lo contrario, continua con los siguientes pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Define la información del proyecto\n",
    "    PROJECT_ID = \"your-project-id\" # @param {type:\"string\"}\n",
    "    LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "\n",
    "    # Inicializa Vertex AI\n",
    "    import vertexai\n",
    "\n",
    "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sólo para uso en entorno de desarrollo local - configurar las credenciales de aplicación por defecto (ADC)**\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <strong>\n",
    "    ⚠️ Importante:\n",
    "  </strong> Este proceso se debe realizar sólo una vez. Si ejecutaste\n",
    "  una libreta con anterioridad, no es necesario ejecutarlo de nuevo.\n",
    "</div>\n",
    "\n",
    "En el caso que estés ejecutando esta libreta en un entorno de desarrollo local, necesitarás configurar las credenciales de aplicaciones por defecto (ADC). ADC es una estrategia usada por las librerías de Google para automáticamente encontrar credenciales de acceso basadas en el entorno de la aplicación. Para ello, sigue los siguientes pasos:\n",
    "\n",
    "- [Instala y configura la herramienta gcloud CLI](https://cloud.google.com/sdk/docs/install)\n",
    "- Crea el archivo de credenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importa las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "from vertexai.generative_models import (\n",
    "  GenerationConfig,\n",
    "  GenerativeModel,\n",
    "  Image,\n",
    "  Part\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa el modelo `Gemini 1.5 Pro Vision`\n",
    "\n",
    "Gemini Pro Vision (`gemini-1.5-pro-vision`) es un modelo multimodal que admite indicaciones multimodales. Puede incluir texto, imágenes y videos en sus solicitudes de avisos y obtener respuestas en texto o código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = GenerativeModel('gemini-1.5-pro-vision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define algunas funciones auxiliares\n",
    "\n",
    "Define algunas funciones auxiliares. Estas funciones **no** son necesarias para trabajar con Gemini Pro Vision, las usamos para visualizar las imágenes y videos que mandamos como parte de la entrada aquí en la libreta de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "def display_images(\n",
    "  images: typing.Iterable[Image],\n",
    "  max_width: int = 600,\n",
    "  max_height: int = 350\n",
    ") -> None:\n",
    "  for image in images:\n",
    "    pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "\n",
    "    if pil_image.mode != 'RGB':\n",
    "      # RGB es soportado por todos los entornos Jupyter\n",
    "      pil_image = pil_image.convert('RGB')\n",
    "\n",
    "    image_width, image_height = pil_image.size\n",
    "\n",
    "    if max_width < image_width or max_height < image_height:\n",
    "      # Redimensiona para mostrar la imagen más pequeña en la libreta\n",
    "      pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "\n",
    "    IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "  def get_image_bytes_from_url (image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "      response = typing.cast(http.client.HTTPResponse, response)\n",
    "      image_bytes = response.read()\n",
    "\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "  def load_image_from_url (image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "  def display_content_as_image (content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Image):\n",
    "      return False\n",
    "\n",
    "    display_images([ content ])\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "  def display_content_as_video (content: str | Image | Part) -> bool:\n",
    "    if not isinstance(content, Part):\n",
    "      return False\n",
    "\n",
    "    part = typing.cast(Part, content)\n",
    "    file_path = part.file_data.file_uri.removeprefix('gs://')\n",
    "    video_url = f'https://storage.googleapis.com/{file_path}'\n",
    "\n",
    "    IPython.display.display(IPython.display.Video(video_url, width=600))\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "  def print_multimodal_prompt (contents: list[ str | Image | Part ]):\n",
    "    for content in contents:\n",
    "      if display_content_as_image(content):\n",
    "        continue\n",
    "      if display_content_as_video(content):\n",
    "        continue\n",
    "      \n",
    "      print(content)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
