{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini: Una descripción general de los escenarios multimodales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visión General\n",
    "\n",
    "### Gemini\n",
    "\n",
    "Gemini es una familia de modelos generativos de IA desarrollados por Google DeepMind y diseñados para casos de uso multimodales. La API Gemini da acceso a los modelos Gemini Pro y Gemini Pro Vision\n",
    "\n",
    "### API Vertex AI Gemini\n",
    "\n",
    "La API Vertex AI Gemini nos da una interfaz unificada para interactuar con modelos Gemini. Actualmente existen dos modelos disponibles en la API Gemini:\n",
    "\n",
    "- **Modelos Gemini Pro** (`gemini-pro`): Diseñado para manejar tareas de lenguaje natural, chat multiturno de texto y código y generación de código.\n",
    "- **Modelo Gemini Pro Vision** (`gemini-pro-vision`): Soporta prompts multimodales. Puedes incluir texto, imágenes y video en los prompt y obtener respuestas en texto o código.\n",
    "\n",
    "Puedes interactuar con la API Gemini usando los siguientes métodos:\n",
    "\n",
    "- Usando [Vertex AI Studio](https://cloud.google.com/generative-ai-studio) para pruebas rápidas y generación de contenidos de texto.\n",
    "- Usando el SDK de Vertex AI\n",
    "\n",
    "Esta libreta se concentra en el uso de **Vertex AI SDK para Python** para utilizar la API Vertex AI Gemini.\n",
    "\n",
    "Para obtener más información, consulta la documentación [IA Generativa en Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos\n",
    "\n",
    "Esta libreta demuestra una variedad de casos de uso multimodal para los que se puede utilizar Gemini.\n",
    "\n",
    "#### Casos de uso multimodales\n",
    "\n",
    "En comparación con los LLM (*Large Language Model*, modelos grandes de lenguaje) de sólo texto, la multimodalidad de Gemini Pro Vision se puede utilizar para muchos casos de uso nuevos:\n",
    "\n",
    "Ejemplos de casos de uso con **texto e imágenes** como entrada:\n",
    "\n",
    "- Detectar objetos en fotografías\n",
    "- Comprender las pantallas y las interfaces\n",
    "- Compresión de dibujos y abstracciones\n",
    "- Comprender gráficos y diagramas\n",
    "- Recomendación de imágenes basada en las preferencias del usuario\n",
    "- Comparar imágenes en busca de similitudes, anomalías o diferencias\n",
    "\n",
    "Ejemplos de casos de uso con **texto y video** como entrada:\n",
    "\n",
    "- Generar la descripción de un video\n",
    "- Extraer etiquetas de objetos a lo largo de un video\n",
    "- Extraer momentos destacados/mensajes de un video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costos\n",
    "\n",
    "Este tutorial usa los siguientes componentes de Google Cloud que pueden generar costos en su factura:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Para mayores detalles puedes revisar los [precios de Vertex AI](https://cloud.google.com/vertex-ai/pricing) y usar la [calculadora de precios](https://cloud.google.com/products/calculator/) para generar una estimación de costos con base en el uso del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeros pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instala el SDK de Vertex AI\n",
    "\n",
    "**Importante:** sólo ejecuta la siguiente línea si estás trabajando en Google Colab, o bien si es la primera libreta que ejecutas en un entorno de desarrollo local. Si ya instalaste las librerías en tu equipo local, no es necesario volver a hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sólo para uso en Colab - Autentica tu ambiente de trabajo**\n",
    "\n",
    "En el caso que estés ejecutando esta libreta en un Google Colab, descomenta la siguiente celda para realizar la autenticación de la sesión en la libreta con Google Cloud. Este paso es importante **para la utilización en Colab**, así podemos garantizar que las llamadas a las APIs de Google Cloud funcionen sin problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import sys\n",
    "# Autenticacion adicional se necesita en Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Autentica el usuario con Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sólo para uso en Colab - define el proyecto en Google Cloud a utilizar**\n",
    "\n",
    "En el caso que estés ejecutando esta libreta en Google Colab, descomenta la siguiente celda para definir qué proyecto en Google Cloud será usado por Colab en la ejecución de esta libreta. De lo contrario, continua con los siguientes pasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Define la información del proyecto\n",
    "    PROJECT_ID = \"your-project-id\" # @param {type:\"string\"}\n",
    "    LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
    "\n",
    "    # Inicializa Vertex AI\n",
    "    import vertexai\n",
    "\n",
    "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sólo para uso en entorno de desarrollo local - configurar las credenciales de aplicación por defecto (ADC)**\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "  <strong>\n",
    "    ⚠️ Importante:\n",
    "  </strong> Este proceso se debe realizar sólo una vez. Si ejecutaste\n",
    "  una libreta con anterioridad, no es necesario ejecutarlo de nuevo.\n",
    "</div>\n",
    "\n",
    "En el caso que estés ejecutando esta libreta en un entorno de desarrollo local, necesitarás configurar las credenciales de aplicaciones por defecto (ADC). ADC es una estrategia usada por las librerías de Google para automáticamente encontrar credenciales de acceso basadas en el entorno de la aplicación. Para ello, sigue los siguientes pasos:\n",
    "\n",
    "- [Instala y configura la herramienta gcloud CLI](https://cloud.google.com/sdk/docs/install)\n",
    "- Crea el archivo de credenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importa las bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "from vertexai.generative_models import (\n",
    "  GenerationConfig,\n",
    "  GenerativeModel,\n",
    "  Image,\n",
    "  Part\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa el modelo `Gemini 1.0 Pro Vision`\n",
    "\n",
    "Gemini Pro Vision (`gemini-1.0-pro-vision`) es un modelo multimodal que admite indicaciones multimodales. Puede incluir texto, imágenes y videos en sus solicitudes de avisos y obtener respuestas en texto o código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = GenerativeModel('gemini-1.0-pro-vision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define algunas funciones auxiliares\n",
    "\n",
    "Define algunas funciones auxiliares. Estas funciones **no** son necesarias para trabajar con Gemini Pro Vision, las usamos para visualizar las imágenes y videos que mandamos como parte de la entrada aquí en la libreta de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "def display_images(\n",
    "  images: typing.Iterable[Image],\n",
    "  max_width: int = 600,\n",
    "  max_height: int = 350\n",
    ") -> None:\n",
    "  for image in images:\n",
    "    pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "\n",
    "    if pil_image.mode != 'RGB':\n",
    "      # RGB es soportado por todos los entornos Jupyter\n",
    "      pil_image = pil_image.convert('RGB')\n",
    "\n",
    "    image_width, image_height = pil_image.size\n",
    "\n",
    "    if max_width < image_width or max_height < image_height:\n",
    "      # Redimensiona para mostrar la imagen más pequeña en la libreta\n",
    "      pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "\n",
    "    IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url (image_url: str) -> bytes:\n",
    "  with urllib.request.urlopen(image_url) as response:\n",
    "    response = typing.cast(http.client.HTTPResponse, response)\n",
    "    image_bytes = response.read()\n",
    "\n",
    "  return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url (image_url: str) -> Image:\n",
    "  image_bytes = get_image_bytes_from_url(image_url)\n",
    "  return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def display_content_as_image (content: str | Image | Part) -> bool:\n",
    "  if not isinstance(content, Image):\n",
    "    return False\n",
    "\n",
    "  display_images([ content ])\n",
    "\n",
    "  return True\n",
    "\n",
    "\n",
    "def display_content_as_video (content: str | Image | Part) -> bool:\n",
    "  if not isinstance(content, Part):\n",
    "    return False\n",
    "\n",
    "  part = typing.cast(Part, content)\n",
    "  file_path = part.file_data.file_uri.removeprefix('gs://')\n",
    "  video_url = f'https://storage.googleapis.com/{file_path}'\n",
    "\n",
    "  IPython.display.display(IPython.display.Video(video_url, width=600))\n",
    "\n",
    "  return True\n",
    "\n",
    "\n",
    "def print_multimodal_prompt (contents: list[ str | Image | Part ]):\n",
    "  for content in contents:\n",
    "    if display_content_as_image(content):\n",
    "      continue\n",
    "    if display_content_as_video(content):\n",
    "      continue\n",
    "    \n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprender el contexto en varias imágenes\n",
    "\n",
    "Una de las capacidades de Gemini es poder razonar a través de múltiples imágenes.\n",
    "\n",
    "Aquí hay un ejemplo del uso de Gemini para calcular el costo total de los alimentos usando una imagen de frutas y una lista de precios:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grocery_url = 'https://storage.googleapis.com/jcaguilar-dot-dev/frutas.png'\n",
    "image_prices_url = 'https://storage.googleapis.com/jcaguilar-dot-dev/precios.png'\n",
    "image_grocery = load_image_from_url(image_grocery_url)\n",
    "image_prices = load_image_from_url(image_prices_url)\n",
    "\n",
    "instrucciones = 'Instrucciones: Considera la siguiente imagen que contiene frutas'\n",
    "prompt1 = '¿Cuánto pagaré por las frutas considerando esta lista de precios?'\n",
    "prompt2 = \"\"\"\n",
    "Responde la pregunta a través de estos pasos:\n",
    "Paso 1: Identifica qué tipo de fruta hay en la primera imagen.\n",
    "Paso 2: Cuenta la cantidad de cada fruta.\n",
    "Paso 3: Por cada artículo en la primera imagen, verifica el precio del artículo en la tabla de precios\n",
    "Paso 4: Calcula el precio subtotal de cada tipo de fruta.\n",
    "Paso 5: Calcula el precio total de las frutas usando los subtotales.\n",
    "Paso 6: Si pago con un billete de $100, ¿cuánto cambio recibiré?\n",
    "\n",
    "Responde y describe los pasos seguidos.\n",
    "\"\"\"\n",
    "\n",
    "contenidos = [\n",
    "  instrucciones,\n",
    "  image_grocery,\n",
    "  prompt1,\n",
    "  image_prices,\n",
    "  prompt2\n",
    "]\n",
    "\n",
    "respuesta = multi_model.generate_content(contenidos, stream=True)\n",
    "\n",
    "print('---------- Prompt ----------')\n",
    "print_multimodal_prompt(contenidos)\n",
    "\n",
    "print('\\n---------- Respuesta ----------')\n",
    "for fragmento in respuesta:\n",
    "  print(fragmento.text, end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprender las pantallas y las interfaces\n",
    "\n",
    "Gemini también puede extraer información de las pantallas de los dispositivos, interfaces de usuario, capturas de pantalla, íconos y diseños.\n",
    "\n",
    "Por ejemplo, si ingresas una imagen de una estufa, puedes perdirle a Gemini que proporcione instrucciones para ayudar al usuario a navegar por la interfaz y responder en diferentes idiomas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stove_url = 'https://storage.googleapis.com/jcaguilar-dot-dev/stove.jpg'\n",
    "image_stove = load_image_from_url(image_stove_url)\n",
    "\n",
    "prompt = \"\"\"\n",
    "¿Cómo puedo configurar el reloj en este dispositivo?\n",
    "Si las instrucciones incluyen botones, explica también dónde están ubicados\n",
    "físicamente esos botones.\n",
    "\n",
    "Por favor, proporciona tres versiones de instrucciones: en español, en portugués\n",
    "y en francés.\n",
    "\"\"\"\n",
    "\n",
    "contenido = [image_stove, prompt]\n",
    "\n",
    "respuesta = multi_model.generate_content(contenido, stream=True)\n",
    "\n",
    "print('\\n---------- Prompt ----------')\n",
    "print_multimodal_prompt(contenido)\n",
    "\n",
    "print('\\n---------- Respuesta ----------')\n",
    "for fragmento in respuesta:\n",
    "  print(fragmento.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Es posible que la respuesta no sea del todo precisa, ya que el modelo puede _alucinar_; sin embargo, el modelo es capaz de identificar la ubicación de los botones y traducirla en una única consulta. Para mitigar las alucinaciones, un enfoque es fundamentar el LLM con técnicas como RAG, que está fuera del alcance de este tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprender la relación entre entidades en diagramas técnicos\n",
    "\n",
    "Gemini tiene capacidades multimodales que le permiten comprender diagramas y realizar pasos prácticos como optimización o generación de código. Este ejemplo demuestra como Gemini puede descifrar un diagrama de entidad-relación (ER), comprender las relaciones entre tablas, identificar los requisitos de optimización en un entorno específico como BigQuery e incluso generar el código correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_er_url = 'https://storage.googleapis.com/jcaguilar-dot-dev/db.png'\n",
    "image_er = load_image_from_url(image_er_url)\n",
    "\n",
    "prompt = \"Por favor, documenta las entidades y relaciones en este diagrama de entidad-relación.\"\n",
    "\n",
    "contenido = [image_er, prompt]\n",
    "\n",
    "# Usa una configuración más determinista con baja temperatura\n",
    "config = GenerationConfig(\n",
    "  temperature=0.1,\n",
    "  top_p=0.8,\n",
    "  top_k=40,\n",
    "  candidate_count=1,\n",
    "  max_output_tokens=2048\n",
    ")\n",
    "\n",
    "respuesta = multi_model.generate_content(\n",
    "  contenido, \n",
    "  generation_config=config, \n",
    "  stream=True\n",
    ")\n",
    "\n",
    "print('\\n---------- Prompt ----------')\n",
    "print_multimodal_prompt(contenido)\n",
    "\n",
    "print('\\n---------- Respuesta ----------')\n",
    "for fragmento in respuesta:\n",
    "  print(fragmento.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendaciones basadas en múltiples imágenes\n",
    "\n",
    "Gemini puede comparar imágenes y proporcionar recomendaciones. Esto puede resultar útil en sectores como el comercio electrónico y el comercio minorista.\n",
    "\n",
    "A continuación se muestra un ejemplo de cómo elegir qué par de gafas serían las más adecuadas para una cara ovalada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_glasses_url1 = 'https://storage.googleapis.com/jcaguilar-dot-dev/glasses1.jpg'\n",
    "image_glasses_url2 = 'https://storage.googleapis.com/jcaguilar-dot-dev/glasses2.jpg'\n",
    "image_glasses1 = load_image_from_url(image_glasses_url1)\n",
    "image_glasses2 = load_image_from_url(image_glasses_url2)\n",
    "\n",
    "prompt1 = \"\"\"\n",
    "¿Cuál de estas gafas me recomiendas según la forma de mi cara?\n",
    "Tengo una cara ovalada.\n",
    "---\n",
    "Gafas 1:\n",
    "\"\"\"\n",
    "prompt2 = \"\"\"\n",
    "---\n",
    "Gafas 2:\n",
    "\"\"\"\n",
    "prompt3 = \"\"\"\n",
    "---\n",
    "Explica cómo tomas esta decisión.\n",
    "Proporciona tu recomendación según la forma de mi cara y el razonamiento\n",
    "para cada una.\n",
    "\"\"\"\n",
    "\n",
    "contenidos = [\n",
    "  prompt1,\n",
    "  image_glasses1,\n",
    "  prompt2,\n",
    "  image_glasses2,\n",
    "  prompt3\n",
    "]\n",
    "\n",
    "respuesta = multi_model.generate_content(contenidos, stream=True)\n",
    "\n",
    "print('\\n---------- Prompt ----------')\n",
    "print_multimodal_prompt(contenidos)\n",
    "\n",
    "print('\\n---------- Respuesta ----------')\n",
    "for fragmento in respuesta:\n",
    "  print(fragmento.text, end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitudes y diferencias\n",
    "\n",
    "Los modelos Gemini pueden comparar imágenes e identificar similitudes o diferencias entre objetos.\n",
    "\n",
    "El siguiente ejemplo muestra dos escenas de Marienplatz en Münich, Alemania, que son ligeramente diferentes. Gemini puede comparar imágenes y encontrar similitudes/diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_landmark1_url = 'https://storage.googleapis.com/jcaguilar-dot-dev/landmark1.jpg'\n",
    "image_landmark2_url = 'https://storage.googleapis.com/jcaguilar-dot-dev/landmark2.jpg'\n",
    "image_landmark1 = load_image_from_url(image_landmark1_url)\n",
    "image_landmark2 = load_image_from_url(image_landmark2_url)\n",
    "\n",
    "prompt1 = \"\"\"\n",
    "Considera las siguientes imágenes:\n",
    "Imagen 1:\n",
    "\"\"\"\n",
    "prompt2 = \"\"\"\n",
    "Imagen 2:\n",
    "\"\"\"\n",
    "prompt3 = \"\"\"\n",
    "Responde las siguientes preguntas en una frase corta.\n",
    "\n",
    "1. ¿Qué se muestra en la Imagen 1?\n",
    "2. ¿En qué se parecen las dos imágenes?\n",
    "3. ¿Cuál es la diferencia entre la Imagen 1 y la Imagen 2 en términos de contenido?\n",
    "\"\"\"\n",
    "\n",
    "contenidos = [\n",
    "  prompt1,\n",
    "  image_landmark1,\n",
    "  prompt2,\n",
    "  image_landmark2,\n",
    "  prompt3\n",
    "]\n",
    "\n",
    "config = GenerationConfig(\n",
    "  temperature=0.0,\n",
    "  top_p=0.2,\n",
    "  top_k=40,\n",
    "  candidate_count=1,\n",
    "  max_output_tokens=2048\n",
    ")\n",
    "\n",
    "respuesta = multi_model.generate_content(\n",
    "  contenidos,\n",
    "  generation_config=config,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "print('\\n---------- Prompt ----------')\n",
    "print_multimodal_prompt(contenidos)\n",
    "\n",
    "print('\\n---------- Respuesta ----------')\n",
    "for fragmento in respuesta:\n",
    "  print(fragmento.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando una descripción de video\n",
    "\n",
    "Gemini también puede extraer etiquetas de un video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "¿Qué se muestra en este video?\n",
    "¿Dónde debería ir para ver esto?\n",
    "¿Cuáles son otros 5 lugares en el mundo que se parecen a este?\n",
    "\"\"\"\n",
    "\n",
    "video = Part.from_uri(\n",
    "  uri='gs://jcaguilar-dot-dev/mediterranean.mp4',\n",
    "  mime_type='video/mp4'\n",
    ")\n",
    "\n",
    "contenidos = [prompt, video]\n",
    "\n",
    "respuesta = multi_model.generate_content(contenidos, stream=True)\n",
    "\n",
    "print('\\n---------- Prompt ----------')\n",
    "print_multimodal_prompt(contenidos)\n",
    "\n",
    "print('\\n---------- Respuesta ----------')\n",
    "for fragmento in respuesta:\n",
    "  print(fragmento.text, end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Puedes confirmar que la ubicación es Antalya, Turquía, visitando la página de Wikipedia: https://en.wikipedia.org/wiki/Antalya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraer etiquetas de objetos a lo largo del video\n",
    "\n",
    "Gemini también puede extraer etiquetas de un video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Responde las siguientes preguntas usando solo el video:\n",
    "- ¿Qué hay en el video?\n",
    "- ¿Cuál es la acción en el video?\n",
    "- ¿Puedes proporcionar 10 etiquetas principales para este video?\n",
    "\"\"\"\n",
    "\n",
    "video = Part.from_uri(\n",
    "  uri='gs://jcaguilar-dot-dev/photo.mp4',\n",
    "  mime_type='video/mp4'\n",
    ")\n",
    "\n",
    "contenidos = [prompt, video]\n",
    "\n",
    "respuesta = multi_model.generate_content(contenidos, stream=True)\n",
    "\n",
    "print('\\n---------- Prompt ----------')\n",
    "print_multimodal_prompt(contenidos)\n",
    "\n",
    "print('\\n---------- Respuesta ----------')\n",
    "for fragmento in respuesta:\n",
    "  print(fragmento.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacer más preguntas sobre un video\n",
    "\n",
    "A continuación se muestra otro ejemplo para usar con Gemini en este escenario de preguntas en video.\n",
    "\n",
    "> **Nota:** Aunque el video contiene audio, Gemini actualmente no admite entrada de audio y sólo responderá según el video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "¿Qué línea es esta?\n",
    "¿A dónde va esto?\n",
    "¿Cuáles son las estaciones/paradas?\n",
    "\"\"\"\n",
    "\n",
    "video = Part.from_uri(\n",
    "  uri='gs://jcaguilar-dot-dev/train.mp4',\n",
    "  mime_type='video/mp4'\n",
    ")\n",
    "\n",
    "contenidos = [prompt, video]\n",
    "\n",
    "respuesta = multi_model.generate_content(contenidos, stream=True)\n",
    "\n",
    "print('\\n---------- Prompt ----------') \n",
    "print_multimodal_prompt(contenidos)\n",
    "\n",
    "print('\\n---------- Respuesta ----------')\n",
    "for fragmento in respuesta:\n",
    "  print(fragmento.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Puedes confirmar que esta es efectivamente la Línea Confederada en Wikipedia aquí: https://en.wikipedia.org/wiki/Confederation_Line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
